{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balraj4347/Create-database-in-spark/blob/main/Spark_database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running Pyspark in Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "wfdMShyG7LgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "DwRT422I7iNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you installed Spark and Java in Colab, it is time to set the environment path which enables you to run Pyspark in your Colab environment. Set the location of Java and Spark by running the following code:"
      ],
      "metadata": {
        "id": "TR-dfvr870Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "!ls /usr/lib/jvm/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "angarXE47w5D",
        "outputId": "72a38c27-7e41-41f1-9a6c-42e01bf3582a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default-java\t\t   java-11-openjdk-amd64     java-8-openjdk-amd64\n",
            "java-1.11.0-openjdk-amd64  java-1.8.0-openjdk-amd64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "rD17-eom73cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeOahfpx8CG3",
        "outputId": "579e6828-3aa2-4884-b862-17088e976312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (7.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pHL152_G7XIm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx4YhqU4eaGF"
      },
      "source": [
        "# Create database in spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X9P83RsefVc"
      },
      "source": [
        "Even Roll no. : Spark\n",
        "\n",
        "Task:\n",
        "Create a database:\n",
        "student(student_id, name,(subject1:marks, subject2:marks),name,(subject1:marks,subject2:marks),\n",
        "\n",
        "student_id, name,(subject1:marks, subject2:marks))\n",
        "1. Find avg of all the subjects\n",
        "2. Update marks of student2\n",
        "3. Update database by adding one student details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vje3uqwpjx_M",
        "outputId": "5800d1ad-f4ae-44cd-f908-08b930a59df6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'ID': 1, 'Name': 'A', 'sub1': 6, 'sub2': 7},\n",
              " {'ID': 2, 'Name': 'B', 'sub1': 5, 'sub2': 8},\n",
              " {'ID': 3, 'Name': 'C', 'sub1': 7, 'sub2': 9}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data = [{ \"ID\": 1,\"Name\": 'A',\"sub1\": 6,\"sub2\": 7},\n",
        "        { \"ID\": 2,\"Name\": 'B',\"sub1\": 5,\"sub2\": 8},\n",
        "        { \"ID\": 3,\"Name\": 'C',\"sub1\": 7,\"sub2\": 9},\n",
        "        ]\n",
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "52jfc9k5kqii",
        "outputId": "04a80138-eece-485f-b385-ee4e32f67064"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[ID: bigint, Name: string, sub1: bigint, sub2: bigint]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+----+----+\n",
            "| ID|Name|sub1|sub2|\n",
            "+---+----+----+----+\n",
            "|  1|   A|   6|   7|\n",
            "|  2|   B|   5|   8|\n",
            "|  3|   C|   7|   9|\n",
            "+---+----+----+----+\n",
            "\n",
            "root\n",
            " |-- ID: long (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- sub1: long (nullable = true)\n",
            " |-- sub2: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dframe = spark.createDataFrame(data)\n",
        "display(dframe)\n",
        "dframe.show()\n",
        "dframe.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qPJIL_Olf-X",
        "outputId": "741f4c92-326f-481e-bd43-6c5dbc5c7890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+\n",
            "| ID|AVERAGE|\n",
            "+---+-------+\n",
            "|  1|    6.5|\n",
            "|  2|    6.5|\n",
            "|  3|    8.0|\n",
            "+---+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dframe.createOrReplaceTempView(\"db\")\n",
        "sqlDF = spark.sql(\"SELECT ID , (AVG(sub1)+AVG(sub2))/2 AS AVERAGE FROM db GROUP BY ID ORDER BY ID\")\n",
        "sqlDF.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IgAeeR-ptMT",
        "outputId": "53c5bbc6-cce9-4548-8411-15b1d17e2af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+----+----+\n",
            "| ID|Name|sub1|sub2|\n",
            "+---+----+----+----+\n",
            "|  1|   A|   6|   7|\n",
            "|  2|   B|  10|   8|\n",
            "|  3|   C|   7|   9|\n",
            "|  4|   D|   4|   5|\n",
            "+---+----+----+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when\n",
        "dframe = dframe.withColumn(\"sub1\", when(dframe.ID == \"2\",\"10\") \\\n",
        "      .otherwise(dframe.sub1))\n",
        "dframe.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3SMkEGKk1kA",
        "outputId": "f213ae34-4e0b-44e6-c6f5-eaf8fd62ecf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+----+----+\n",
            "| ID|Name|sub1|sub2|\n",
            "+---+----+----+----+\n",
            "|  1|   A|   6|   7|\n",
            "|  2|   B|   5|   8|\n",
            "|  3|   C|   7|   9|\n",
            "|  4|   D|   4|   5|\n",
            "+---+----+----+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "unknown_list = [['4', 'D','4','5']]\n",
        "df2 = spark.createDataFrame(unknown_list)\n",
        "dframe = dframe.union(df2)\n",
        "dframe.show();\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Spark database.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOIoxJyP16FRdMJfGs5N1QE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}